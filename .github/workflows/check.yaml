name: Check for broken links

on:
  workflow_dispatch:
    inputs:
      site:
        required: true
        type: string
        default: https://www.brimdata.io/

# Link checker config details as of November 19, 2025
# ===================================================
#
# --timeout 300
#
#   Avoids timeout failures checking www.postgresql.org.
#
# --max-connections=5
# --max-connections-per-host=2
# --rate-limit=10
#
#    A gentler crawl config vs. the defaults which caused timeouts to many
#    random URLs. This combo was recommened by Claude AI and not only
#    eliminated timeouts but brought run time down from 5 minutes to <1 minute.
#
# --buffer-size=16384
#
#   Avoids "error when reading response headers: small read buffer. Increase ReadBufferSize."
#   on github.com URLs.
#
# --header="User-Agent:Mozilla/5.0"
#
#   Trying to look more like a legit browser prevents HTTP 403 errors on
#   wikipedia and zeek.org.
#
# --exclude github.com.*#
#
#   Due to "not found" failures when crawling GitHub fragment identifiers
#   dynamically generated via JavaScript. See https://github.com/raviqqe/muffet/issues/144.
#   Links covered by this:
#   - https://github.com/google/zetasql/blob/master/docs/pipe-syntax.md#pipe-operator-semantics
#   - https://github.com/jqlang/jq/wiki/jq-Language-Description#the-jq-language
# 
# --exclude https://dl.acm.org/doi/pdf/10.1145/984549.984551
# --exclude https://www.researchgate.net/publication/221325979_Union_Types_for_Semistructured_Data
#
#   Due to HTTP 403 errors when crawled. Academic sites are notorious for
#   blocking crawlers as is their right, so conventional wisdom is to exclude.
#
# --exclude https://github.com/lz4/lz4/blob/master/doc/lz4_Block_format.md
#
#   Due to intermittent HTTP 429 errors when crawled. May be due to the same
#   topic discussed in https://github.com/orgs/community/discussions/157887
#   though it's not clear why our other github.com links consistently check ok.

jobs:
  broken-linkcheck:
    runs-on: ubuntu-latest
    steps:
      - name: Check for broken links
        uses: ruzickap/action-my-broken-link-checker@v2
        with:
          url: ${{ inputs.site }}
          cmd_params:
            --verbose
            --timeout 300
            --max-connections=5
            --max-connections-per-host=2
            --rate-limit=10
            --buffer-size=16384
            --header="User-Agent:Mozilla/5.0"
